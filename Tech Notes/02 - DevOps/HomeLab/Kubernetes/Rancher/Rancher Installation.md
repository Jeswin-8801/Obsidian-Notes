---
tags: [installation,rancher,kubernetes,k3s]
---

</br>

> [!info] 
> Setup Helm before running the commands below by following [[Helm Installation]]

** Run the following sections of code on the separate VM that was created to setup the HA cluster in [[K3s Setup#Configuring VMs as a HA Kubernetes cluster]] **

</br>

## Create a Namespace for Rancher

```bash ln:False
kubectl create namespace cattle-system
```

</br>

## Install Cert Manager

#### kubectl appy

> The Rancher management server is designed to be secure by default and requires SSL/TLS configuration. Therefore, requires HTTPS.
> 
> The certs are generated by cert manager and used my the web services to host over HTTPS.

```bash ln:False
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.17.2/cert-manager.yaml
```

** Find the install command with the latest version of ==Cert Manager== over at [kubectl apply - cert-manager Documentation](https://cert-manager.io/docs/installation/kubectl/)**

#### Helm

- add repo
```bash ln:False
# Add the Jetstack Helm repository  
helm repo add jetstack https://charts.jetstack.io  
  
# Update your local Helm chart repository cache  
helm repo update
```

- Install the cert-manager Helm chart
```bash ln:False
helm install cert-manager jetstack/cert-manager \
  --namespace cert-manager \
  --create-namespace \
  --set crds.enabled=true
```

> [!Help] 
> If for some reason, the above command doesn't work try:
> ```bash ln:False
> helm template cert-manager jetstack/cert-manager --namespace cert-manager | kubectl apply -f -
> ```
> 
> Source: [Error installing Cert-manager, ServiceAccount cert-manager-cainjector already exist · Issue #2540 · cert-manager/cert-manager](https://github.com/cert-manager/cert-manager/issues/2540)

### Verify Deployment

Verify it is deployed correctly by checking the cert-manager namespace for running pod:

```bash ln:False
kubectl get pods --namespace cert-manager
```

</br>


## Install Rancher with Helm

```bash ln:False
helm install rancher rancher-stable/rancher \
  --namespace cattle-system \
  --set hostname=rancher.homelab.pve \
  --set bootstrapPassword=admin
```

> Note the usage of `rancher-stable/rancher` and the flag as we have installed the stable version above.

- wait until <mark style="background: #D2B3FFA6;">Rancher</mark> is rolled out by checking though the command
```bash ln:False
kubectl -n cattle-system rollout status deploy/rancher
```

</br>

## Verify Rancher is successfully Deployed

```bash ln:False
$ kubectl -n cattle-system get deploy rancher
NAME      READY   UP-TO-DATE   AVAILABLE   AGE
rancher   3/3     3            3           8m19s
```

**This means that we have three instances running on our cluster, one on each master node.**

But,

We find that Rancher is not exposed through the Load Balancer IP if we run.

```bash ln:False
kubectl get svc -n cattle-system
```

- Expose the Rancher service on the Load Balancer using the command

```bash ln:False
kubectl expose deployment rancher --name rancher-lb --port=443 --type=LoadBalancer -n cattle-system rancher-lb exposed
```

gives the output:

```
service/rancher-lb exposed
Error from server (NotFound): deployments.apps "rancher-lb" not found
Error from server (NotFound): deployments.apps "exposed" not found
```

We can ignore the error messages as we are using self signed certificates.

Running the below command gives the exposed IP of Rancher:

```bash ln:False
 $ kubectl get svc -n cattle-system
NAME                       TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)          AGE
imperative-api-extension   ClusterIP      10.43.56.146    <none>         6666/TCP         26m
rancher                    ClusterIP      10.43.143.236   <none>         80/TCP,443/TCP   27m
rancher-lb                 LoadBalancer   10.43.139.242   192.168.0.61   443:31220/TCP    4m8s
rancher-webhook            ClusterIP      10.43.49.42     <none>         443/TCP          25m
```

> Rancher can now be accessed through the URL https://192.168.0.61/ as per the IP specified above